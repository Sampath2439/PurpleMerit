# Multi-Agent Marketing System - End-to-End Architecture Guide

## üèóÔ∏è System Overview

The Multi-Agent Marketing System is a sophisticated, production-ready application that uses AI agents to automate lead triage, engagement, and campaign optimization. The system is built with a microservices architecture and supports both local development and Docker deployment.

## üéØ Core Components

### 1. **Agent System**
- **Lead Triage Agent (LT-001)**: Automatically classifies and scores incoming leads using ML models
- **Engagement Agent (EN-001)**: Manages personalized multi-channel outreach and communication
- **Campaign Optimization Agent (OP-001)**: Monitors and optimizes campaign performance using data-driven strategies

### 2. **Orchestration Layer**
- **Agent Orchestrator**: Routes requests between agents and manages handoffs
- **MCP Server**: Model Context Protocol server for secure inter-agent communication
- **Memory System**: Manages short-term, long-term, episodic, and semantic memory

### 3. **Data Processing Pipeline**
- **Data Processor**: Handles data ingestion, cleaning, and feature engineering
- **ML Pipeline**: Trains ensemble models for lead scoring and campaign optimization
- **Memory Management**: Stores and retrieves agent experiences and knowledge

### 4. **API Layer**
- **Flask Application**: RESTful API endpoints for agent interactions
- **User Management**: Authentication and authorization system
- **Health Monitoring**: System status and performance metrics

### 5. **Frontend Dashboard**
- **React-like Interface**: Modern web dashboard for system monitoring
- **Real-time Updates**: Live system status and agent performance
- **Interactive Testing**: Test agents and view results in real-time

## üîÑ End-to-End Workflow

### 1. **Lead Processing Workflow**
```
Lead Input ‚Üí Triage Agent ‚Üí Scoring & Classification ‚Üí Engagement Agent ‚Üí Multi-channel Outreach ‚Üí Campaign Optimization ‚Üí Performance Analysis
```

**Detailed Steps:**
1. **Lead Ingestion**: New leads are received via API or data import
2. **Triage Processing**: Lead Triage Agent analyzes lead data and assigns scores
3. **Routing Decision**: System determines next action based on lead score and type
4. **Engagement**: Engagement Agent creates personalized outreach campaigns
5. **Optimization**: Campaign Optimization Agent monitors performance and suggests improvements
6. **Memory Storage**: All interactions are stored in the memory system for learning

### 2. **Campaign Optimization Workflow**
```
Campaign Data ‚Üí Performance Analysis ‚Üí ML Model Training ‚Üí Optimization Recommendations ‚Üí A/B Testing ‚Üí Results Integration
```

**Detailed Steps:**
1. **Data Collection**: Campaign performance data is gathered from multiple sources
2. **Analysis**: ML models analyze performance patterns and identify optimization opportunities
3. **Recommendations**: System generates actionable optimization suggestions
4. **Implementation**: Changes are applied to campaigns automatically or with approval
5. **Monitoring**: Continuous monitoring of optimization results
6. **Learning**: Results are fed back into the ML models for continuous improvement

## üê≥ Docker Deployment

### Prerequisites
- Docker and Docker Compose installed
- At least 4GB RAM available
- Ports 5000, 5432, 6379, and 7474 available

### 1. **Docker Compose Setup**

The system uses Docker Compose to orchestrate multiple services:

```yaml
version: '3.8'
services:
  web:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - DATABASE_URL=postgresql://user:password@db:5432/marketing_db
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
      - neo4j

  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=marketing_db
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:6-alpine
    volumes:
      - redis_data:/data

  neo4j:
    image: neo4j:4.4
    environment:
      - NEO4J_AUTH=neo4j/password
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
```

### 2. **Dockerfile Configuration**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create data directory
RUN mkdir -p /app/data

# Expose port
EXPOSE 5000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

# Start application
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "src.main:app"]
```

### 3. **Deployment Commands**

```bash
# Build and start all services
docker-compose up --build -d

# View logs
docker-compose logs -f

# Scale web service
docker-compose up --scale web=3 -d

# Stop services
docker-compose down

# Stop and remove volumes
docker-compose down -v
```

## üöÄ Local Development Setup

### 1. **Environment Setup**
```bash
# Clone repository
git clone <repository_url>
cd multi_agent_marketing_system

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate.ps1
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. **Database Setup**
```bash
# Create database directory
mkdir database

# Initialize database (automatic on first run)
python src/main.py
```

### 3. **Start Development Server**
```bash
# Start the application
python src/main.py

# Or use the startup script
python start.py
```

## üìä API Endpoints

### Core Endpoints
- `GET /` - Frontend dashboard
- `GET /health` - System health check
- `GET /api/health` - User service health
- `GET /api/agents/health` - Agent system health

### Agent Endpoints
- `POST /api/agents/triage` - Lead triage processing
- `POST /api/agents/engage` - Lead engagement
- `POST /api/agents/optimize` - Campaign optimization
- `POST /api/agents/handoff` - Agent handoff execution

### Memory Endpoints
- `POST /api/agents/memory/store` - Store agent memory
- `GET /api/agents/memory/retrieve` - Retrieve agent memory

### Analytics Endpoints
- `GET /api/agents/analytics/performance` - Performance metrics
- `GET /api/agents/system/status` - System status

## üîß Configuration

### Environment Variables
```bash
# Flask Configuration
FLASK_ENV=development
SECRET_KEY=your-secret-key

# Database Configuration
DATABASE_URL=sqlite:///database/app.db
# For production: postgresql://user:password@host:port/dbname

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
```

### Agent Configuration
```python
# Agent settings in src/agents.py
AGENT_CONFIG = {
    'triage': {
        'confidence_threshold': 0.8,
        'max_processing_time': 30,
        'memory_ttl': 24
    },
    'engagement': {
        'max_channels': 5,
        'response_timeout': 60,
        'retry_attempts': 3
    },
    'optimization': {
        'analysis_interval': 3600,
        'min_data_points': 100,
        'optimization_threshold': 0.1
    }
}
```

## üìà Monitoring and Logging

### 1. **Application Logs**
```bash
# View application logs
docker-compose logs -f web

# View specific service logs
docker-compose logs -f db
docker-compose logs -f redis
```

### 2. **Performance Monitoring**
- **Health Checks**: Automatic health monitoring every 30 seconds
- **Metrics Collection**: Performance metrics stored in Redis
- **Error Tracking**: Comprehensive error logging and tracking

### 3. **System Metrics**
- Agent response times
- Memory usage statistics
- Database performance metrics
- API endpoint response times

## üîí Security Features

### 1. **Authentication**
- JWT-based authentication
- Role-based access control (RBAC)
- Session management with expiration

### 2. **Data Protection**
- Password hashing with bcrypt
- SQL injection prevention
- CORS configuration
- Input validation and sanitization

### 3. **Network Security**
- HTTPS support in production
- Firewall configuration
- Rate limiting on API endpoints

## üß™ Testing

### 1. **Unit Tests**
```bash
# Run all tests
python -m pytest src/tests.py

# Run specific test categories
python -m pytest src/tests.py::TestAgentSystem
python -m pytest src/tests.py::TestDataProcessing
```

### 2. **Integration Tests**
```bash
# Test API endpoints
python test_system.py

# Test Docker deployment
docker-compose -f docker-compose.test.yml up --build
```

### 3. **Load Testing**
```bash
# Install load testing tools
pip install locust

# Run load tests
locust -f tests/load_test.py --host=http://localhost:5000
```

## üöÄ Production Deployment

### 1. **Production Configuration**
```bash
# Set production environment
export FLASK_ENV=production
export SECRET_KEY=your-production-secret-key

# Use production database
export DATABASE_URL=postgresql://user:password@prod-db:5432/marketing_db
```

### 2. **Scaling Considerations**
- **Horizontal Scaling**: Use multiple web service instances
- **Database Scaling**: Consider read replicas for high traffic
- **Caching**: Implement Redis clustering for high availability
- **Load Balancing**: Use nginx or cloud load balancer

### 3. **Backup Strategy**
```bash
# Database backup
docker-compose exec db pg_dump -U user marketing_db > backup.sql

# Volume backup
docker run --rm -v multi_agent_marketing_system_postgres_data:/data -v $(pwd):/backup alpine tar czf /backup/postgres_backup.tar.gz /data
```

## üîÑ CI/CD Pipeline

### 1. **GitHub Actions Workflow**
```yaml
name: CI/CD Pipeline
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: python -m pytest

  deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Deploy to production
        run: |
          docker-compose -f docker-compose.prod.yml up -d
```

## üìö Troubleshooting

### Common Issues

1. **Port Already in Use**
   ```bash
   # Find process using port 5000
   netstat -ano | findstr :5000
   # Kill process
   taskkill /PID <PID> /F
   ```

2. **Database Connection Issues**
   ```bash
   # Check database status
   docker-compose exec db pg_isready
   # Reset database
   docker-compose down -v && docker-compose up -d
   ```

3. **Memory Issues**
   ```bash
   # Check memory usage
   docker stats
   # Increase Docker memory limit
   # Docker Desktop > Settings > Resources > Memory
   ```

### Performance Optimization

1. **Database Optimization**
   - Add database indexes
   - Optimize queries
   - Use connection pooling

2. **Caching Strategy**
   - Implement Redis caching
   - Cache frequently accessed data
   - Use CDN for static assets

3. **Code Optimization**
   - Profile application performance
   - Optimize database queries
   - Implement async processing

## üìû Support

For issues and questions:
- Check the logs: `docker-compose logs -f`
- Review the API documentation
- Test individual components
- Check system resources (CPU, memory, disk)

## üîÑ Updates and Maintenance

### Regular Maintenance Tasks
1. **Database Maintenance**: Regular backups and cleanup
2. **Security Updates**: Keep dependencies updated
3. **Performance Monitoring**: Monitor system metrics
4. **Log Rotation**: Manage log file sizes
5. **Health Checks**: Verify system health regularly

This comprehensive guide covers the entire system architecture, from development to production deployment, ensuring you have all the information needed to understand, deploy, and maintain the Multi-Agent Marketing System.
